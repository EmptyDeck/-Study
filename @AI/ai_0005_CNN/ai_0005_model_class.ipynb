{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Handwriting recognition using CNN\n",
    "Conv2d & Maxpool\n",
    "\n",
    "helpfull website : \n",
    "Conv2d, ConvTranspose2d, MaxPool2d Calculator : http://layer-calc.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n",
      "Mon Jan 30 01:24:44 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.02       Driver Version: 528.02       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 42%   29C    P8    12W / 180W |   7987MiB /  8192MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     14712      C   ...Data\\Anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     48424      C   ...Data\\Anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     50340      C   ...Data\\Anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "##Hardware\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cuda torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "  ! nvidia-smi\n",
    "elif torch.backends.mps.is_available() == True:\n",
    "  print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "  \n",
    "    super(CNN,self).__init__()\n",
    "    \n",
    "    self.conv1 = torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.maxpoo1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    self.conv2 = torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "    self.maxpoo2 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    self.fc = torch.nn.Linear(7*7*64,10,bias=True) # this shows the input and output\n",
    "    \n",
    "  def forward(self,x):\n",
    "    \n",
    "    out = self.conv1(x)\n",
    "    out = self.relu1(out)\n",
    "    out = self.maxpoo1(out)\n",
    "    out = self.conv2(out)\n",
    "    out = self.relu2(out)\n",
    "    out = self.maxpoo2(out)\n",
    "    out = self.fc(out)\n",
    "    \n",
    "    return out\n",
    "    \"\"\"\n",
    "\"\"\"    \n",
    "method = input(\"1 : resnet // 2 : veg  // 3 L alexnet\")\n",
    "if method == '1':\n",
    "  method = \"resnet\"\n",
    "elif method == '2':\n",
    "  method = \"vgg\"\n",
    "elif method == '3':\n",
    "  method = \"alexnet\"\n",
    "else:\n",
    "  print(\" I didnt understand, just going to use alexnet anyway\")\n",
    "  method = \"alexnet\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import torchvision.models as models\n",
    "\n",
    "if method == \"resnet\":\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "elif method == \"vgg\":\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10, bias=True)\n",
    "elif method == \"alexnet\":\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10, bias=True)\n",
    "else:\n",
    "    raise ValueError(\"Check Method!\")\n",
    "\"\"\"\n",
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self,dropout_rate=0.2):\n",
    "    super().__init__()\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.layer1 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels=1,out_channels=96,kernel_size=11,stride=4,padding=0),#227 to 55// (227-2*0-11)/4 + 1\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.MaxPool2d(kernel_size=3,stride=2)#55 to 27\n",
    "      )\n",
    "    \n",
    "    self.layer2 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5,stride=1,padding=2),##27 to 27\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.MaxPool2d(kernel_size=3,stride=2)#27 to 13\n",
    "    ) # this shows the input and output\n",
    "    self.layer3 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(256, 384, 3, 1, 1),#to 13\n",
    "      torch.nn.ReLU()\n",
    "    )\n",
    "    self.layer4 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(384, 384, 3, 1, 1),#to 13\n",
    "        torch.nn.ReLU()\n",
    "    )\n",
    "    self.layer5 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(384, 256, 3, 1, 1),#to 13\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(3, 2)#13 to 6\n",
    "    )\n",
    "    \n",
    "    self.fc1 = torch.nn.Linear(256 * 6 * 6,4096)#256 nurons with 6*6 pic\n",
    "    \n",
    "    self.fc2 = torch.nn.Linear(4096,4096)\n",
    "    self.fc3 = torch.nn.Linear(4096,10) #bias is true in default\n",
    "    \n",
    "  def forward(self,x):\n",
    "    out = self.layer1(x)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "    out = self.layer5(out)\n",
    "    out = out.view(out.size(0),-1)\n",
    "    \n",
    "    #print(f\"out shape before fc1: {out.shape}\")\n",
    "    out = torch.nn.functional.relu(self.fc1(out))\n",
    "    out = torch.nn.functional.dropout(out,self.dropout_rate)\n",
    "    #print(f\"out shape before fc2: {out.shape}\")\n",
    "    out = torch.nn.functional.relu(self.fc2(out))\n",
    "    out = torch.nn.functional.dropout(out,self.dropout_rate)\n",
    "    out = self.fc3(out)\n",
    "    out = torch.nn.functional.log_softmax(out,dim=1)\n",
    "    \n",
    "    return out\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  15\n",
      "Batch size :  10\n",
      "dropout :  0.3\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 15\n",
    "batch_size = 10\n",
    "drop_out_posibility = 0.3\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "  print(\"dropout : \",drop_out_posibility)\n",
    "show_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a \"transformation pipeline\" called \"AlexTransform\" using the transforms.Compose() function from the PyTorch library's transforms module. The pipeline is composed of three separate transformations that will be applied in sequence to any data passed through it.  \n",
    "\n",
    "transforms.Resize((227, 227)): This transformation resizes the input data to have a height and width of 227 pixels each.  \n",
    "transforms.ToTensor(): This transformation converts the input data from a PIL image to a PyTorch tensor.  \n",
    "transforms.Normalize((0.1307,), (0.3081,)): This transformation normalizes the input data by subtracting the mean and dividing by the standard deviation. The mean and standard deviation are provided as arguments (0.1307 and 0.3081 respectively) which represent the mean and standard deviation of the MNIST dataset.  \n",
    "So, in summary, the AlexTransform pipeline will resize any input data to (227, 227), convert it to a PyTorch tensor and normalize it using the mean and std of the MNIST dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexTransform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and downloading the MNIST dataset\n",
    "\n",
    "mnist_train= data.MNIST(root='MNIST_data',\n",
    "                        train = True, #bring train data\n",
    "                        transform=AlexTransform,\n",
    "                        download=True)\n",
    "mnist_test = data.MNIST(root='MNIST_data',\n",
    "                        train=False,\n",
    "                        transform=AlexTransform,\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: MNIST_data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(227, 227), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  10\n",
      "Batch size :  30\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 10\n",
    "batch_size = 30\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "show_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, #batch size at parameters\n",
    "                                          shuffle=True, #mix it up\n",
    "                                          drop_last=True) #len(data)%batch = left overs shoud I drop this or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [['1layer','SGD'],['5layer','SGD'],['1layer','Adam'],['5layer','Adam'],['5layer+drop','SGD'],['5layer+drop','Adam']] \n",
    "models = ['Adam']\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def choose_model(LR,optim):\n",
    "  global model\n",
    "  global optimzier\n",
    "  \n",
    "  if optim == 'SGD':\n",
    "    optimzier = torch.optim.SGD(model.parameters(),lr=LR)\n",
    "    #print(\"SGD\")\n",
    "  elif optim == 'Adam':\n",
    "    optimzier = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "    #print(\"Adam\")\n",
    "  else:\n",
    "    print(\"Error unknown optim option please check models list\")\n",
    "\n",
    "\n",
    "choose_model(LR_list[0],models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  10\n",
      "Batch size :  30\n"
     ]
    }
   ],
   "source": [
    "show_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14712\\1103735257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#change image to 1 dim list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_len = len(data_loader)\n",
    "\n",
    "for LR in LR_list:\n",
    "  for optim in models:\n",
    "    choose_model(LR,optim)#function chooseing model\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epoch+1)):\n",
    "      model.train()\n",
    "      avg_cost = 0\n",
    "      for X , Y in (data_loader):\n",
    "        \n",
    "        #change image to 1 dim list\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        #reset grad\n",
    "        optimzier.zero_grad()\n",
    "        #foward\n",
    "        hypothesis = model(X)\n",
    "        #Error\n",
    "        cost = loss(hypothesis,Y)\n",
    "        # Backparopagation\n",
    "        cost.backward()\n",
    "        #cal weight\n",
    "        optimzier.step()\n",
    "        #avr cal\n",
    "        avg_cost = avg_cost + cost/batch_len\n",
    "      #if epoch % (nb_epoch / 11) == 0:\n",
    "      #print(\"%f\"%cost.item())\n",
    "    ## ACC\n",
    "  print(\"LR :  %.0E Cost : %f\"%(LR,cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.42 %% accuracy\n"
     ]
    }
   ],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(dataset=mnist_test) #batch size at parameters)\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  wrong_cnt = 0\n",
    "  for X_test,Y_test in data_loader_test:\n",
    "    X_test = X_test.to(device)\n",
    "    Y_test = Y_test.to(device)\n",
    "    if torch.argmax(model(X_test)) != Y_test:\n",
    "      wrong_cnt += 1\n",
    "  print((len(data_loader_test)-wrong_cnt)/len(data_loader_test)*100,\"%% accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didnt took me a lot to code. Because only the model changed  \n",
    "Learning how to do it took a long time though."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--update 2023/01/29 1628i--  \n",
    "used AlexTransform for getter result  \n",
    "\n",
    "2023/01/29 0309i  \n",
    "I have to go to sleep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
