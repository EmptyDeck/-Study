{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Handwriting recognition using CNN\n",
    "Conv2d & Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n",
      "Sun Jan 29 03:04:00 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.02       Driver Version: 528.02       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 42%   37C    P8     9W / 180W |   3899MiB /  8192MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      9600      C   ...Data\\Anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "##Hardware\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cuda torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "  ! nvidia-smi\n",
    "elif torch.backends.mps.is_available() == True:\n",
    "  print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NN,self).__init__()\n",
    "    inputnum = 784\n",
    "    nnnnum = 512\n",
    "    output = 10\n",
    "    self.liner1 = torch.nn.Linear(inputnum,nnnnum,bias=True)\n",
    "    self.liner2 = torch.nn.Linear(nnnnum,nnnnum,bias=True)\n",
    "    self.liner3 = torch.nn.Linear(nnnnum,nnnnum,bias=True)\n",
    "    self.liner4 = torch.nn.Linear(nnnnum,nnnnum,bias=True)\n",
    "    self.liner5 = torch.nn.Linear(nnnnum,output,bias=True)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    torch.nn.init.xavier_normal_(self.liner1.weight)\n",
    "    torch.nn.init.xavier_normal_(self.liner2.weight)\n",
    "    torch.nn.init.xavier_normal_(self.liner3.weight)\n",
    "    torch.nn.init.xavier_normal_(self.liner4.weight)\n",
    "    torch.nn.init.xavier_normal_(self.liner5.weight)\n",
    "    \n",
    "  def foward(self,x):\n",
    "    \n",
    "    out = self.liner1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.liner2(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.liner3(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.liner4(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.liner5(out)\n",
    "    \n",
    "    return out\n",
    "  \n",
    "model = NN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CNN,self).__init__()\n",
    "    \n",
    "    self.conv1 = torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.maxpoo1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    self.conv2 = torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "    self.maxpoo2 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    self.fc = torch.nn.Linear(7*7*64,10,bias=True) # this shows the input and output\n",
    "    \n",
    "  def forward(self,x):\n",
    "    \n",
    "    out = self.conv1(x)\n",
    "    out = self.relu1(out)\n",
    "    out = self.maxpoo1(out)\n",
    "    out = self.conv2(out)\n",
    "    out = self.relu2(out)\n",
    "    out = self.maxpoo2(out)\n",
    "    out = self.fc(out)\n",
    "    \n",
    "    return out\n",
    "    \"\"\"\n",
    "  def __init__(self):\n",
    "    super(CNN,self).__init__()\n",
    "    \n",
    "    self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    \n",
    "    self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.MaxPool2d(kernel_size=2,stride=2)) # this shows the input and output\n",
    "    self.fc = torch.nn.Linear(7*7*64,10,bias=True)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    out = self.layer1(x)\n",
    "    out = self.layer2(out)\n",
    "    out = out.view(out.size(0),-1)\n",
    "    out = self.fc(out)\n",
    "    \n",
    "    return out\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  15\n",
      "Batch size :  10\n",
      "dropout :  0.3\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 15\n",
    "batch_size = 10\n",
    "drop_out_posibility = 0.3\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "  print(\"dropout : \",drop_out_posibility)\n",
    "show_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train= data.MNIST(root='MNIST_data',\n",
    "                        train = True, #bring train data\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "mnist_test = data.MNIST(root='MNIST_data',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  8\n",
      "Batch size :  10\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 8\n",
    "batch_size = 10\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "show_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, #batch size at parameters\n",
    "                                          shuffle=True, #mix it up\n",
    "                                          drop_last=True) #len(data)%batch = left overs shoud I drop this or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [['1layer','SGD'],['5layer','SGD'],['1layer','Adam'],['5layer','Adam'],['5layer+drop','SGD'],['5layer+drop','Adam']] \n",
    "models = ['SGD','Adam']\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def choose_model(LR,optim):\n",
    "  global model\n",
    "  global optimzier\n",
    "  \n",
    "  if optim == 'SGD':\n",
    "    optimzier = torch.optim.SGD(model.parameters(),lr=LR)\n",
    "    #print(\"SGD\")\n",
    "  elif optim == 'Adam':\n",
    "    optimzier = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "    #print(\"Adam\")\n",
    "  else:\n",
    "    print(\"Error unknown optim option please check models list\")\n",
    "\n",
    "\n",
    "choose_model(LR_list[0],models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  8\n",
      "Batch size :  10\n"
     ]
    }
   ],
   "source": [
    "show_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:15<02:03, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:30<01:44, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.199220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:44<01:29, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.160242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:59<01:14, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [01:14<00:59, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [01:29<00:44, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.313513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [01:44<00:29, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [01:59<00:15, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:14<00:00, 14.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.074633\n",
      "LR : 1E-03 #SGD # optim Avr Cost : #0.098073#  Acc: 97.510 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:18<02:24, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:36<02:08, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:53<01:46, 17.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [01:10<01:27, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [01:27<01:09, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [01:45<00:51, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [02:02<00:34, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [02:19<00:17, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:37<00:00, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000309\n",
      "LR : 1E-03 #Adam # optim Avr Cost : #0.009200#  Acc: 97.440 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_len = len(data_loader)\n",
    "\n",
    "for LR in learning_rate:\n",
    "  for optim in models:\n",
    "    choose_model(LR,optim)#function chooseing model\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epoch+1)):\n",
    "      avg_cost = 0\n",
    "      for X , Y in (data_loader):\n",
    "        \n",
    "        #change image to 1 dim list\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        #reset grad\n",
    "        optimzier.zero_grad()\n",
    "        #foward\n",
    "        hypothesis = model(X)\n",
    "        #Error\n",
    "        cost = loss(hypothesis,Y)\n",
    "        # Backparopagation\n",
    "        cost.backward()\n",
    "        #cal weight\n",
    "        optimzier.step()\n",
    "        #avr cal\n",
    "        avg_cost = avg_cost + cost/batch_len\n",
    "      #if epoch % (nb_epoch / 11) == 0:\n",
    "      print(\"%f\"%cost.item())\n",
    "    ## ACC\n",
    "    with torch.no_grad():\n",
    "      X_test = mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)\n",
    "      Y_test = mnist_test.test_labels.to(device)\n",
    "      \n",
    "      prediction = model(X_test)\n",
    "      correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "      accuracy = correct_prediction.float().mean()\n",
    "    print(\"LR : %.0E #%s # optim Avr Cost : #%f#  Acc: %.3F %%\"%(LR,optim,avg_cost,accuracy.item()*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didnt took me a lot to code. Because only the model changed  \n",
    "Learning how to do it took a long time though."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023/01/29 0309i  \n",
    "I have to go to sleep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
