{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Study \n",
    "using many methods at once with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardwere\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cuda torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "elif torch.backends.mps.is_available() == True:\n",
    "  print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  15\n",
      "Batch size :  100\n",
      "dropout :  0.3\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 15\n",
    "batch_size = 100\n",
    "drop_out_posibility = 0.3\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "  print(\"dropout : \",drop_out_posibility)\n",
    "show_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train= data.MNIST(root='MNIST_data',\n",
    "                        train = True, #bring train data\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "mnist_test = data.MNIST(root='MNIST_data',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, #batch size at parameters\n",
    "                                          shuffle=True, #mix it up\n",
    "                                          drop_last=True) #len(data)%batch = left overs shoud I drop this or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defalt\n"
     ]
    }
   ],
   "source": [
    "##One layer model\n",
    "linear1 = torch.nn.Linear(784,10,bias=True)\n",
    "##Five layer model\n",
    "linear51 = torch.nn.Linear(784,512,bias=True)\n",
    "linear52 = torch.nn.Linear(512,512,bias=True)\n",
    "linear53 = torch.nn.Linear(512,512,bias=True)\n",
    "linear54 = torch.nn.Linear(512,512,bias=True)\n",
    "linear55 = torch.nn.Linear(512,10,bias=True)\n",
    "\n",
    "\n",
    "##Line model\n",
    "relu = torch.nn.ReLU()\n",
    "#dropout\n",
    "dropout = torch.nn.Dropout(p=drop_out_posibility)\n",
    "#loss\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "models = [['1layer','SGD'],['5layer','SGD'],['1layer','Adam'],['5layer','Adam'],['5layer+drop','SGD'],['5layer+drop','Adam']]\n",
    "\n",
    "\n",
    "def choose_model(LR,layer,optim):\n",
    "  global model\n",
    "  global optimzier\n",
    "  if layer == '1layer':\n",
    "    torch.nn.init.normal_(linear1.weight)\n",
    "    model = torch.nn.Sequential(linear1).to(device)\n",
    "    #print(\"layer1\")\n",
    "  elif layer == '5layer':\n",
    "    torch.nn.init.normal_(linear51.weight)\n",
    "    torch.nn.init.normal_(linear52.weight)\n",
    "    torch.nn.init.normal_(linear53.weight)\n",
    "    torch.nn.init.normal_(linear54.weight)\n",
    "    torch.nn.init.normal_(linear55.weight)\n",
    "    model = torch.nn.Sequential(linear51,relu,\n",
    "                                linear52,relu,\n",
    "                                linear53,relu,\n",
    "                                linear54,relu,\n",
    "                                linear55).to(device)\n",
    "    #print(\"layer5\")\n",
    "  elif layer == '5layer+drop':\n",
    "    torch.nn.init.normal_(linear51.weight)\n",
    "    torch.nn.init.normal_(linear52.weight)\n",
    "    torch.nn.init.normal_(linear53.weight)\n",
    "    torch.nn.init.normal_(linear54.weight)\n",
    "    torch.nn.init.normal_(linear55.weight)\n",
    "    model = torch.nn.Sequential(linear51,relu,dropout,\n",
    "                                linear52,relu,dropout,\n",
    "                                linear53,relu,dropout,\n",
    "                                linear54,relu,dropout,\n",
    "                                linear55).to(device)\n",
    "    model.train()#we need this when dropout\n",
    "    #print(\"layer5 drop\")\n",
    "  else:\n",
    "    print(\"Error : Unknown Layer option please check models list\")\n",
    "  if optim == 'SGD':\n",
    "    optimzier = torch.optim.SGD(model.parameters(),lr=LR)\n",
    "    #print(\"SGD\")\n",
    "  elif optim == 'Adam':\n",
    "    optimzier = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "    #print(\"Adam\")\n",
    "  else:\n",
    "    print(\"Error unknown optim option please check models list\")\n",
    "\n",
    "print(\"defalt\")\n",
    "choose_model(LR_list[0],models[0][0],models[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.normal_(linear51.weight)\n",
    "torch.nn.init.normal_(linear52.weight)\n",
    "torch.nn.init.normal_(linear53.weight)\n",
    "torch.nn.init.normal_(linear54.weight)\n",
    "torch.nn.init.normal_(linear55.weight)\n",
    "model = torch.nn.Sequential(linear51,relu,dropout,\n",
    "                            linear52,relu,dropout,\n",
    "                            linear53,relu,dropout,\n",
    "                            linear54,relu,dropout,\n",
    "                            linear55).to(device)\n",
    "model.train()#we need this when dropout\n",
    "optimzier = torch.optim.Adam(model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:21<00:00,  5.44s/it]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #1layer#  layer ,#SGD#  optim model Avr Cost : #4.166#  Accuracy : 39.650 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:26<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer#  layer ,#SGD#  optim model Avr Cost : #nan#  Accuracy : 9.800 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:19<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #1layer#  layer ,#Adam#  optim model Avr Cost : #0.399#  Accuracy : 88.950 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:26<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer#  layer ,#Adam#  optim model Avr Cost : #nan#  Accuracy : 9.800 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:24<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer+drop#  layer ,#SGD#  optim model Avr Cost : #nan#  Accuracy : 9.800 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:26<00:00,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer+drop#  layer ,#Adam#  optim model Avr Cost : #nan#  Accuracy : 9.800 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_len = len(data_loader)\n",
    "\n",
    "for LR in LR_list:\n",
    "  for layer,optim in models:\n",
    "    choose_model(LR,layer,optim)#function chooseing model\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epoch)):\n",
    "      avg_cost = 0\n",
    "      for X , Y in (data_loader):\n",
    "        \n",
    "        #change image to 1 dim list\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        #reset grad\n",
    "        optimzier.zero_grad()\n",
    "        #foward\n",
    "        hypothesis = model(X)\n",
    "        #Error\n",
    "        cost = loss(hypothesis,Y)\n",
    "        # Backparopagation\n",
    "        cost.backward()\n",
    "        #cal weight\n",
    "        optimzier.step()\n",
    "        #avr cal\n",
    "        avg_cost = avg_cost + cost/batch_len\n",
    "    ## ACC\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "      Y_test = mnist_test.test_labels.to(device)\n",
    "      \n",
    "      prediction = model(X_test)\n",
    "      correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "      accuracy = correct_prediction.float().mean()\n",
    "    print(\"With %.0E Learning rate #%s#  layer ,#%s#  optim model Avr Cost : #%.3f#  Accuracy : %.3F %%\"%(LR,layer,optim,avg_cost,accuracy.item()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  8\n",
      "Prediction:  0\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 테스트\n",
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "print('Label: ', Y_single_data.item())\n",
    "single_prediction = model(X_single_data)\n",
    "print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 숫자 눈으로 뿌려보기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_single_data.reshape(28,28).cpu())\n",
    "print(Y_single_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
