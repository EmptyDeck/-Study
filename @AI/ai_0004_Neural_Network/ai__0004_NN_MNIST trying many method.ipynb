{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Study \n",
    "using many methods at once with MNIST data\n",
    "\n",
    "\n",
    "\n",
    "My code explanation may appear to indicate that my English skills are poor, but that is not the case. I am intentionally using fewer words for the purpose of making it easier to read and understand.    \n",
    "look :  my code explain is bad. i do it to make you read fast    \n",
    "\n",
    "Code Explain :   \n",
    "\n",
    "This code is MNIST data code. Hand Writing image guess code.  \n",
    "Hardware part use gpu in pc and mac.  \n",
    "Random seed fix is to make same result every time  \n",
    "Parameters have infomation about learning rate, epoch, batch size, drop out  \n",
    "  \n",
    "about model see 'models' list  \n",
    "'models' list show number of layer and optimizer and drop  \n",
    "5 layers models use init.xavier_normal to make model good  \n",
    "In ML part they use all kinds of models and show result  \n",
    "At last test part . they pick one and show one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardware\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cuda torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "elif torch.backends.mps.is_available() == True:\n",
    "  print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning list :  [10000, 100, 1, 0.01, 0.0001, 1e-06, 1e-08]\n",
      "Learning rate :  [0.001]\n",
      "Nb_epoch :  15\n",
      "Batch size :  10\n",
      "dropout :  0.3\n"
     ]
    }
   ],
   "source": [
    "LR_list = [10000,100,1,1e-2,1e-4,1e-6,1e-8]\n",
    "learning_rate = [1e-3]\n",
    "nb_epoch = 15\n",
    "batch_size = 10\n",
    "drop_out_posibility = 0.3\n",
    "def show_parameters():\n",
    "  print(\"Learning list : \",LR_list)\n",
    "  print(\"Learning rate : \",learning_rate)\n",
    "  print(\"Nb_epoch : \",nb_epoch)\n",
    "  print(\"Batch size : \",batch_size)\n",
    "  print(\"dropout : \",drop_out_posibility)\n",
    "show_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train= data.MNIST(root='MNIST_data',\n",
    "                        train = True, #bring train data\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "mnist_test = data.MNIST(root='MNIST_data',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, #batch size at parameters\n",
    "                                          shuffle=True, #mix it up\n",
    "                                          drop_last=True) #len(data)%batch = left overs shoud I drop this or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defalt\n"
     ]
    }
   ],
   "source": [
    "##One layer model\n",
    "linear1 = torch.nn.Linear(784,10,bias=True)\n",
    "\n",
    "##Five layer model\n",
    "linear51 = torch.nn.Linear(784,512,bias=True)\n",
    "linear52 = torch.nn.Linear(512,512,bias=True)\n",
    "linear53 = torch.nn.Linear(512,512,bias=True)\n",
    "linear54 = torch.nn.Linear(512,512,bias=True)\n",
    "linear55 = torch.nn.Linear(512,10,bias=True)\n",
    "\n",
    "\n",
    "##Line model\n",
    "relu = torch.nn.ReLU()\n",
    "#dropout\n",
    "dropout = torch.nn.Dropout(p=drop_out_posibility)\n",
    "#loss\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "models = [['1layer','SGD'],['5layer','SGD'],['1layer','Adam'],['5layer','Adam'],['5layer+drop','SGD'],['5layer+drop','Adam']]\n",
    "\n",
    "\n",
    "def choose_model(LR,layer,optim):\n",
    "  global model\n",
    "  global optimzier\n",
    "  if layer == '1layer':\n",
    "    torch.nn.init.normal_(linear1.weight)\n",
    "    model = torch.nn.Sequential(linear1).to(device)\n",
    "    #print(\"layer1\")\n",
    "  elif layer == '5layer':\n",
    "    torch.nn.init.xavier_normal_(linear51.weight)##\n",
    "    torch.nn.init.xavier_normal_(linear52.weight)\n",
    "    torch.nn.init.xavier_normal_(linear53.weight)\n",
    "    torch.nn.init.xavier_normal_(linear54.weight)\n",
    "    torch.nn.init.xavier_normal_(linear55.weight)\n",
    "    model = torch.nn.Sequential(linear51,relu,\n",
    "                                linear52,relu,\n",
    "                                linear53,relu,\n",
    "                                linear54,relu,\n",
    "                                linear55).to(device)\n",
    "    #print(\"layer5\")\n",
    "  elif layer == '5layer+drop':\n",
    "    torch.nn.init.xavier_normal_(linear51.weight)\n",
    "    torch.nn.init.xavier_normal_(linear52.weight)\n",
    "    torch.nn.init.xavier_normal_(linear53.weight)\n",
    "    torch.nn.init.xavier_normal_(linear54.weight)\n",
    "    torch.nn.init.xavier_normal_(linear55.weight)\n",
    "    model = torch.nn.Sequential(linear51,relu,dropout,\n",
    "                                linear52,relu,dropout,\n",
    "                                linear53,relu,dropout,\n",
    "                                linear54,relu,dropout,\n",
    "                                linear55).to(device)\n",
    "    model.train()#we need this when dropout\n",
    "    #print(\"layer5 drop\")\n",
    "  else:\n",
    "    print(\"Error : Unknown Layer option please check models list\")\n",
    "  if optim == 'SGD':\n",
    "    optimzier = torch.optim.SGD(model.parameters(),lr=LR)\n",
    "    #print(\"SGD\")\n",
    "  elif optim == 'Adam':\n",
    "    optimzier = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "    #print(\"Adam\")\n",
    "  else:\n",
    "    print(\"Error unknown optim option please check models list\")\n",
    "\n",
    "\n",
    "choose_model(LR_list[0],models[0][0],models[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:05<00:00,  8.34s/it]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #1layer#  layer ,#SGD#  optim model Avr Cost : #1.051#  Accuracy : 78.950 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:55<00:00, 11.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer#  layer ,#SGD#  optim model Avr Cost : #0.094#  Accuracy : 96.220 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:19<00:00,  9.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #1layer#  layer ,#Adam#  optim model Avr Cost : #0.287#  Accuracy : 86.430 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:57<00:00, 15.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer#  layer ,#Adam#  optim model Avr Cost : #0.040#  Accuracy : 97.850 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:17<00:00, 13.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer+drop#  layer ,#SGD#  optim model Avr Cost : #0.211#  Accuracy : 91.240 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:11<00:00, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1E-03 Learning rate #5layer+drop#  layer ,#Adam#  optim model Avr Cost : #0.180#  Accuracy : 97.520 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_len = len(data_loader)\n",
    "\n",
    "for LR in learning_rate:\n",
    "  for layer,optim in models:\n",
    "    choose_model(LR,layer,optim)#function chooseing model\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epoch)):\n",
    "      avg_cost = 0\n",
    "      for X , Y in (data_loader):\n",
    "        \n",
    "        #change image to 1 dim list\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        #reset grad\n",
    "        optimzier.zero_grad()\n",
    "        #foward\n",
    "        hypothesis = model(X)\n",
    "        #Error\n",
    "        cost = loss(hypothesis,Y)\n",
    "        # Backparopagation\n",
    "        cost.backward()\n",
    "        #cal weight\n",
    "        optimzier.step()\n",
    "        #avr cal\n",
    "        avg_cost = avg_cost + cost/batch_len\n",
    "    ## ACC\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "      Y_test = mnist_test.test_labels.to(device)\n",
    "      \n",
    "      prediction = model(X_test)\n",
    "      correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "      accuracy = correct_prediction.float().mean()\n",
    "    print(\"With %.0E Learning rate #%s#  layer ,#%s#  optim model Avr Cost : #%.3f#  Accuracy : %.3F %%\"%(LR,layer,optim,avg_cost,accuracy.item()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  7\n",
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c62e4d6b80>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random test\n",
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "print('Label: ', Y_single_data.item())\n",
    "single_prediction = model(X_single_data)\n",
    "print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_single_data.reshape(28,28).cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
