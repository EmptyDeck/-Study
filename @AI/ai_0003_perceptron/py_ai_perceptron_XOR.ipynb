{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "solving XOR problem\n",
    "\n",
    "21:47i\n",
    "\n",
    "im tired\n",
    "lets get init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not using NN\n",
    "lets use basic knowlage to learn first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Status Working Well\n",
      "Cude torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardware\n",
    "import torch\n",
    "print(\"GPU Status \",end=\"\")\n",
    "print(\"Working Well\") if torch.cuda.is_available() else print(\"Not good, Activating CPU calculation\")\n",
    "device = 'cuda' if torch.cuda.is_available() else print(\"cant use gpu//using cpu instead\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "templist = [1,2,3]\n",
    "templist = torch.FloatTensor(templist).to(device)\n",
    "print(\"Cude torch working : \",end=\"\")\n",
    "print(templist.is_cuda)\n",
    "print(\"current device no. : \",end=\"\")\n",
    "print(torch.cuda.current_device())\n",
    "print(\"GPU device count : \",end=\"\")\n",
    "print(torch.cuda.device_count())\n",
    "print(\"GPU name : \",end=\"\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"device : \",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.FloatTensor([[0,0], [0,1], [1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.ones([2,1],requires_grad=True,device=device)  #Weights\n",
    "W2 = torch.zeros([2,1],requires_grad=True,device=device)\n",
    "W3 = torch.zeros([2,1],requires_grad=True,device=device)\n",
    "b1 = torch.zeros(1,requires_grad=True,device=device)  #bias\n",
    "b2 = torch.zeros(1,requires_grad=True,device=device)\n",
    "b3 = torch.zeros(1,requires_grad=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.7311],\n",
      "        [0.7311],\n",
      "        [0.8808]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Y1 = torch.sigmoid(X.matmul(W1) + b1)\n",
    "print(Y1)\n",
    "Y2 = torch.sigmoid(X.matmul(W2) + b2)\n",
    "print(Y2)\n",
    "Y12 = torch.cat([Y1,Y2],dim=1)\n",
    "print(Y12.matmul(W3) + b3)\n",
    "print(torch.sigmoid(Y12.matmul(W3) + b3))\n",
    "hypothesis = torch.sigmoid(Y12.matmul(W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 cost : 0.00370\n",
      "epoch : 1000 cost : 0.00265\n",
      "epoch : 2000 cost : 0.00207\n",
      "epoch : 3000 cost : 0.00169\n",
      "epoch : 4000 cost : 0.00143\n",
      "epoch : 5000 cost : 0.00124\n",
      "epoch : 6000 cost : 0.00109\n",
      "epoch : 7000 cost : 0.00098\n",
      "epoch : 8000 cost : 0.00088\n",
      "epoch : 9000 cost : 0.00081\n",
      "epoch : 10000 cost : 0.00074\n",
      "tensor([[8.0373],\n",
      "        [8.0373]], device='cuda:0', requires_grad=True) tensor([-3.7277], device='cuda:0', requires_grad=True)\n",
      "tensor([[6.2834],\n",
      "        [6.2834]], device='cuda:0', requires_grad=True) tensor([-9.5951], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 15.4024],\n",
      "        [-16.1719]], device='cuda:0', requires_grad=True) tensor([-7.3121], device='cuda:0', requires_grad=True)\n",
      "tensor([[9.5636e-04],\n",
      "        [9.9934e-01],\n",
      "        [9.9934e-01],\n",
      "        [6.7938e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([W1,W2,W3,b1,b2,b3],lr=1)\n",
    "\n",
    "nb_epoch = 10000\n",
    "\n",
    "for epoch in range(nb_epoch + 1):\n",
    "  \n",
    "  #reset grad\n",
    "  optimizer.zero_grad()\n",
    "  #Calcualte Forward\n",
    "  Y1 = torch.sigmoid(X.matmul(W1) + b1)\n",
    "  Y2 = torch.sigmoid(X.matmul(W2) + b2)\n",
    "  Y12 = torch.cat([Y1,Y2],dim=1)\n",
    "  hypothesis = torch.sigmoid(Y12.matmul(W3) + b3)\n",
    "  #Error calculation\n",
    "  cost = -(Y * torch.log(hypothesis) + (1 - Y) * torch.log(1 - hypothesis)).mean()\n",
    "  #Backwards calcuation\n",
    "  cost.backward()\n",
    "  #optim renew\n",
    "  optimizer.step()\n",
    "  if epoch % 1000 == 0:\n",
    "    print(\"epoch : %d\"%epoch,\"cost : %.5f\"%cost.item())\n",
    "print(W1,b1)\n",
    "print(W2,b2)\n",
    "print(W3,b3)\n",
    "\n",
    "print(hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): #temporary grad = false\n",
    "\n",
    "  preedicted = (hypothesis > 0.5).float()#float() changes true to 1 and false to 0\n",
    "\n",
    "  accuracy = (preedicted == Y).float().mean()\n",
    "  print(\"accuray : \",accuracy.item()*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
