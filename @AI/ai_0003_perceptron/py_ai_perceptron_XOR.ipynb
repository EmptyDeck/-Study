{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "solving XOR problem\n",
    "\n",
    "21:47i\n",
    "\n",
    "im tired\n",
    "lets get init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not using NN\n",
    "lets use basic knowlage to learn first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Status Working Well\n",
      "Cude torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardware\n",
    "import torch\n",
    "print(\"GPU Status \",end=\"\")\n",
    "print(\"Working Well\") if torch.cuda.is_available() else print(\"Not good, Activating CPU calculation\")\n",
    "device = 'cuda' if torch.cuda.is_available() else print(\"cant use gpu//using cpu instead\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "templist = [1,2,3]\n",
    "templist = torch.FloatTensor(templist).to(device)\n",
    "print(\"Cude torch working : \",end=\"\")\n",
    "print(templist.is_cuda)\n",
    "print(\"current device no. : \",end=\"\")\n",
    "print(torch.cuda.current_device())\n",
    "print(\"GPU device count : \",end=\"\")\n",
    "print(torch.cuda.device_count())\n",
    "print(\"GPU name : \",end=\"\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"device : \",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.FloatTensor([[0,0], [0,1], [1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.ones([2,1],requires_grad=True,device=device)  #Weights\n",
    "W2 = torch.zeros([2,1],requires_grad=True,device=device)\n",
    "W3 = torch.zeros([2,1],requires_grad=True,device=device)\n",
    "b1 = torch.zeros(1,requires_grad=True,device=device)  #bias\n",
    "b2 = torch.zeros(1,requires_grad=True,device=device)\n",
    "b3 = torch.zeros(1,requires_grad=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.7311],\n",
      "        [0.7311],\n",
      "        [0.8808]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Y1 = torch.sigmoid(X.matmul(W1) + b1)\n",
    "print(Y1)\n",
    "Y2 = torch.sigmoid(X.matmul(W2) + b2)\n",
    "print(Y2)\n",
    "Y12 = torch.cat([Y1,Y2],dim=1)\n",
    "print(Y12.matmul(W3) + b3)\n",
    "print(torch.sigmoid(Y12.matmul(W3) + b3))\n",
    "hypothesis = torch.sigmoid(Y12.matmul(W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0026510246098041534\n",
      "1 0.002650262787938118\n",
      "2 0.0026494855992496014\n",
      "3 0.002648798283189535\n",
      "8 0.0026450033765286207\n",
      "9 0.002644286025315523\n",
      "10 0.0026435242034494877\n",
      "11 0.0026427621487528086\n",
      "16 0.0026390566490590572\n",
      "17 0.0026383092626929283\n",
      "18 0.0026375921443104744\n",
      "19 0.002636830322444439\n",
      "24 0.0026331248227506876\n",
      "25 0.0026323627680540085\n",
      "26 0.0026316456496715546\n",
      "27 0.0026308835949748755\n",
      "128 0.002558167092502117\n",
      "129 0.0025574946776032448\n",
      "130 0.002556807594373822\n",
      "131 0.002556060440838337\n",
      "136 0.002552624326199293\n",
      "137 0.0025518923066556454\n",
      "138 0.002551205223426223\n",
      "139 0.0025505328085273504\n",
      "144 0.0025470517575740814\n",
      "145 0.0025463197380304337\n",
      "146 0.0025456473231315613\n",
      "147 0.0025449602399021387\n",
      "152 0.0025415089912712574\n",
      "153 0.0025407769717276096\n",
      "154 0.0025401345919817686\n",
      "155 0.0025394472759217024\n",
      "256 0.002471592742949724\n",
      "257 0.002470920328050852\n",
      "258 0.002470263047143817\n",
      "259 0.002469620667397976\n",
      "264 0.002466364298015833\n",
      "265 0.0024657067842781544\n",
      "266 0.0024651093408465385\n",
      "267 0.0024644669611006975\n",
      "272 0.002461180556565523\n",
      "273 0.002460538176819682\n",
      "274 0.0024598659947514534\n",
      "275 0.0024592233821749687\n",
      "280 0.0024559965822845697\n",
      "281 0.0024553542025387287\n",
      "282 0.0024547120556235313\n",
      "283 0.002454054541885853\n",
      "384 0.0023906573187559843\n",
      "385 0.0023900149390101433\n",
      "386 0.002389372792094946\n",
      "387 0.0023888051509857178\n",
      "392 0.002385757863521576\n",
      "393 0.0023851306177675724\n",
      "394 0.0023844880051910877\n",
      "395 0.0023839203640818596\n",
      "400 0.0023808730766177177\n",
      "401 0.0023802458308637142\n",
      "402 0.002379678189754486\n",
      "403 0.002379035810008645\n",
      "408 0.0023760036565363407\n",
      "409 0.002375406213104725\n",
      "410 0.0023748385719954967\n",
      "411 0.0023741961922496557\n",
      "512 0.002314717508852482\n",
      "513 0.0023141796700656414\n",
      "514 0.0023136120289564133\n",
      "515 0.002313029719516635\n",
      "520 0.0023102066479623318\n",
      "521 0.002309594303369522\n",
      "522 0.002309041563421488\n",
      "523 0.0023084739223122597\n",
      "528 0.0023056063801050186\n",
      "529 0.0023050536401569843\n",
      "530 0.0023044412955641747\n",
      "531 0.0023038885556161404\n",
      "536 0.0023010207805782557\n",
      "537 0.002300468273460865\n",
      "538 0.0022999155335128307\n",
      "539 0.0022993776947259903\n",
      "640 0.0022435029968619347\n",
      "641 0.002242980059236288\n",
      "642 0.0022424275521188974\n",
      "643 0.0022419048473238945\n",
      "648 0.0022391716483980417\n",
      "649 0.002238634042441845\n",
      "650 0.0022381111048161983\n",
      "651 0.0022375585976988077\n",
      "656 0.0022349003702402115\n",
      "657 0.002234362531453371\n",
      "658 0.0022338395938277245\n",
      "659 0.0022333019878715277\n",
      "664 0.0022306137252599\n",
      "665 0.0022300761193037033\n",
      "666 0.0022295534145087004\n",
      "667 0.0022290307097136974\n",
      "768 0.002176490146666765\n",
      "769 0.0021759674418717623\n",
      "770 0.002175459638237953\n",
      "771 0.0021749967709183693\n",
      "776 0.0021724130492657423\n",
      "777 0.0021719648502767086\n",
      "778 0.0021714423783123493\n",
      "779 0.0021709194406867027\n",
      "784 0.0021684104576706886\n",
      "785 0.0021678879857063293\n",
      "786 0.0021673801820725203\n",
      "787 0.0021668574772775173\n",
      "792 0.0021643785294145346\n",
      "793 0.0021638558246195316\n",
      "794 0.0021634078584611416\n",
      "795 0.002162884920835495\n",
      "896 0.0021133197005838156\n",
      "897 0.0021128866355866194\n",
      "898 0.002112379064783454\n",
      "899 0.0021119308657944202\n",
      "904 0.002109481953084469\n",
      "905 0.0021090488880872726\n",
      "906 0.0021085410844534636\n",
      "907 0.0021081077866256237\n",
      "912 0.0021057184785604477\n",
      "913 0.002105225808918476\n",
      "914 0.0021047182381153107\n",
      "915 0.0021042851731181145\n",
      "920 0.0021019107662141323\n",
      "921 0.0021014029625803232\n",
      "922 0.002100969897583127\n",
      "923 0.002100462093949318\n",
      "tensor([[7.5941],\n",
      "        [7.5941]], device='cuda:0', requires_grad=True) tensor([-3.4912], device='cuda:0', requires_grad=True)\n",
      "tensor([[5.7954],\n",
      "        [5.7954]], device='cuda:0', requires_grad=True) tensor([-8.8606], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 13.4811],\n",
      "        [-14.2729]], device='cuda:0', requires_grad=True) tensor([-6.3365], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0026],\n",
      "        [0.9981],\n",
      "        [0.9981],\n",
      "        [0.0019]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([W1,W2,W3,b1,b2,b3],lr=1)\n",
    "\n",
    "nb_epoch = 1000\n",
    "\n",
    "for epoch in range(nb_epoch + 1):\n",
    "  \n",
    "  #reset grad\n",
    "  optimizer.zero_grad()\n",
    "  #Calcualte Forward\n",
    "  Y1 = torch.sigmoid(X.matmul(W1) + b1)\n",
    "  Y2 = torch.sigmoid(X.matmul(W2) + b2)\n",
    "  Y12 = torch.cat([Y1,Y2],dim=1)\n",
    "  hypothesis = torch.sigmoid(Y12.matmul(W3) + b3)\n",
    "  #Error calculation\n",
    "  cost = -(Y * torch.log(hypothesis) + (1 - Y) * torch.log(1 - hypothesis)).mean()\n",
    "  #Backwards calcuation\n",
    "  cost.backward()\n",
    "  #optim renew\n",
    "  optimizer.step()\n",
    "  if epoch & 100 == 0:\n",
    "    print(epoch,cost.item())\n",
    "print(W1,b1)\n",
    "print(W2,b2)\n",
    "print(W3,b3)\n",
    "\n",
    "print(hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): #temporary grad = false\n",
    "\n",
    "  preedicted = (hypothesis > 0.5).float()#float() changes true to 1 and false to 0\n",
    "\n",
    "  accuracy = (preedicted == Y).float().mean()\n",
    "  print(\"accuray : \",accuracy.item()*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
